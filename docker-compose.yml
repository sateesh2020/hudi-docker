version: "3.8"

services:

  namenode:
    image: hudi-hadoop_${HADOOP_VERSION}-namenode:latest
    hostname: namenode
    container_name: namenode
    environment:
      - CLUSTER_NAME=hudi_hadoop_hive_spark
    ports:
      - "50070:50070"
      - "8020:8020"
      # JVM debugging port (will be mapped to a random port on host)
      - "5005"
    env_file:
      - ./hadoop.env
    healthcheck:
      test: ["CMD", "curl", "-f", "http://namenode:50070"]
      interval: 30s
      timeout: 10s
      retries: 3

  datanode1:
    image: hudi-hadoop_${HADOOP_VERSION}-datanode:latest
    container_name: datanode1
    hostname: datanode1
    environment:
      - CLUSTER_NAME=hudi_hadoop_hive_spark
    env_file:
      - ./hadoop.env
    ports:
      - "50075:50075"
      - "50010:50010"
      # JVM debugging port (will be mapped to a random port on host)
      - "5005"
    links:
      - "namenode"
      - "historyserver"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://datanode1:50075"]
      interval: 30s
      timeout: 10s
      retries: 3
    depends_on:
      - namenode

  historyserver:
    image: hudi-hadoop_${HADOOP_VERSION}-historyserver:latest
    hostname: historyserver
    container_name: historyserver
    environment:
      - CLUSTER_NAME=hudi_hadoop_hive_spark
    depends_on:
      - "namenode"
    links:
      - "namenode"
    ports:
      - "58188:8188"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://historyserver:8188"]
      interval: 30s
      timeout: 10s
      retries: 3
    env_file:
      - ./hadoop.env
    volumes:
      - historyserver:/hadoop/yarn/timeline
  
  resourcemanager:
    image: hudi-hadoop_${HADOOP_VERSION}-resourcemanager:latest
    hostname: resourcemanager
    container_name: resourcemanager
    restart: on-failure
    env_file:
      - ./hadoop.env
    ports:
      - 50088:8088
    healthcheck:
      test: ["CMD", "curl", "-f", "http://resourcemanager:8088"]
      interval: 30s
      timeout: 10s
      retries: 3

  nodemanager:
    image: hudi-hadoop_${HADOOP_VERSION}-nodemanager:latest
    hostname: nodemanager
    container_name: nodemanager
    env_file:
      - ./hadoop.env
    ports:
      - 50042:8042
    healthcheck:
      test: ["CMD", "curl", "-f", "http://nodemanager:8042"]
      interval: 30s
      timeout: 10s
      retries: 3
  
  hive-metastore-postgresql:
    image: bde2020/hive-metastore-postgresql:2.3.0
    volumes:
      - hive-metastore-postgresql:/var/lib/postgresql
    hostname: hive-metastore-postgresql
    container_name: hive-metastore-postgresql

  hivemetastore:
    image: hudi-hadoop_${HADOOP_VERSION}-hive_${HIVE_VERSION}:latest
    hostname: hivemetastore
    container_name: hivemetastore
    links:
      - "hive-metastore-postgresql"
      - "namenode"
    env_file:
      - ./hadoop.env
    command: /opt/hive/bin/hive --service metastore
    environment:
      SERVICE_PRECONDITION: "namenode:50070 hive-metastore-postgresql:5432"
    ports:
      - "9083:9083"
      # JVM debugging port (will be mapped to a random port on host)
      - "5005"
    healthcheck:
      test: ["CMD", "nc", "-z", "hivemetastore", "9083"]
      interval: 30s
      timeout: 10s
      retries: 3
    depends_on:
      - "hive-metastore-postgresql"
      - "namenode"

  hiveserver:
    image: ${HUB_USER}/hudi-hadoop_${HADOOP_VERSION}-hive_${HIVE_VERSION}:latest
    hostname: hiveserver
    container_name: hiveserver
    env_file:
      - ./hadoop.env
    environment:
      SERVICE_PRECONDITION: "hivemetastore:9083"
    ports:
      - "10000:10000"
      # JVM debugging port (will be mapped to a random port on host)
      - "5005"
    depends_on:
      - "hivemetastore"
    links:
      - "hivemetastore"
      - "hive-metastore-postgresql"
      - "namenode"
    volumes:
      - ${HUDI_WS}:/var/hoodie/ws

  sparkmaster:
    image: ${HUB_USER}/hudi-hadoop_${HADOOP_VERSION}-hive_${HIVE_VERSION}-sparkmaster_${SPARK_VERSION}:latest
    hostname: sparkmaster
    container_name: sparkmaster
    env_file:
      - ./hadoop.env
    ports:
      - "8080:8080"
      - "7077:7077"
      # JVM debugging port (will be mapped to a random port on host)
      - "5005"
    environment:
      - INIT_DAEMON_STEP=setup_spark
    links:
      - "hivemetastore"
      - "hiveserver"
      - "hive-metastore-postgresql"
      - "namenode"

  spark-worker-1:
    image: ${HUB_USER}/hudi-hadoop_${HADOOP_VERSION}-hive_${HIVE_VERSION}-sparkworker_${SPARK_VERSION}:latest
    hostname: spark-worker-1
    container_name: spark-worker-1
    env_file:
      - ./hadoop.env
    depends_on:
      - sparkmaster
    ports:
      - "8081:8081"
      # JVM debugging port (will be mapped to a random port on host)
      - "5005"
    environment:
      - "SPARK_MASTER=spark://sparkmaster:7077"
    links:
      - "hivemetastore"
      - "hiveserver"
      - "hive-metastore-postgresql"
      - "namenode"

  zookeeper:
    image: 'bitnami/zookeeper:3.4.12-r68'
    hostname: zookeeper
    container_name: zookeeper
    ports:
      - "2181:2181"
    environment:
      - ALLOW_ANONYMOUS_LOGIN=yes

  kafka:
    image: 'bitnami/kafka:2.0.0'
    hostname: kafkabroker
    container_name: kafkabroker
    ports:
      - "9092:9092"
    environment:
      - KAFKA_ZOOKEEPER_CONNECT=zookeeper:2181
      - ALLOW_PLAINTEXT_LISTENER=yes

  presto-coordinator-1:
    container_name: presto-coordinator-1
    hostname: presto-coordinator-1
    image: ${HUB_USER}/hudi-hadoop_${HADOOP_VERSION}-prestobase_${PRESTO_VERSION}:latest
    ports:
      - "8090:8090"
      # JVM debugging port (will be mapped to a random port on host)
      - "5005"
    environment:
      - PRESTO_JVM_MAX_HEAP=512M
      - PRESTO_QUERY_MAX_MEMORY=1GB
      - PRESTO_QUERY_MAX_MEMORY_PER_NODE=256MB
      - PRESTO_QUERY_MAX_TOTAL_MEMORY_PER_NODE=384MB
      - PRESTO_MEMORY_HEAP_HEADROOM_PER_NODE=100MB
      - TERM=xterm
    links:
      - "hivemetastore"
    volumes:
      - ${HUDI_WS}:/var/hoodie/ws
    command: coordinator

  presto-worker-1:
    container_name: presto-worker-1
    hostname: presto-worker-1
    image: ${HUB_USER}/hudi-hadoop_${HADOOP_VERSION}-prestobase_${PRESTO_VERSION}:latest
    depends_on: [ "presto-coordinator-1" ]
    environment:
      - PRESTO_JVM_MAX_HEAP=512M
      - PRESTO_QUERY_MAX_MEMORY=1GB
      - PRESTO_QUERY_MAX_MEMORY_PER_NODE=256MB
      - PRESTO_QUERY_MAX_TOTAL_MEMORY_PER_NODE=384MB
      - PRESTO_MEMORY_HEAP_HEADROOM_PER_NODE=100MB
      - TERM=xterm
    links:
      - "hivemetastore"
      - "hiveserver"
      - "hive-metastore-postgresql"
      - "namenode"
    volumes:
      - ${HUDI_WS}:/var/hoodie/ws
    command: worker

  trino-coordinator-1:
    container_name: trino-coordinator-1
    hostname: trino-coordinator-1
    image: ${HUB_USER}/hudi-hadoop_${HADOOP_VERSION}-trinocoordinator_${TRINO_VERSION}:latest
    ports:
      - "8091:8091"
      # JVM debugging port (will be mapped to a random port on host)
      - "5005"
    links:
      - "hivemetastore"
    volumes:
      - ${HUDI_WS}:/var/hoodie/ws
    command: http://trino-coordinator-1:8091 trino-coordinator-1

  trino-worker-1:
    container_name: trino-worker-1
    hostname: trino-worker-1
    image: ${HUB_USER}/hudi-hadoop_${HADOOP_VERSION}-trinoworker_${TRINO_VERSION}:latest
    depends_on: [ "trino-coordinator-1" ]
    ports:
      - "8092:8092"
      # JVM debugging port (will be mapped to a random port on host)
      - "5005"
    links:
      - "hivemetastore"
      - "hiveserver"
      - "hive-metastore-postgresql"
      - "namenode"
    volumes:
      - ${HUDI_WS}:/var/hoodie/ws
    command: http://trino-coordinator-1:8091 trino-worker-1

  graphite:
    container_name: graphite
    hostname: graphite
    image: graphiteapp/graphite-statsd
    ports:
      - 80:80
      - 2003-2004:2003-2004
      - 8126:8126

  adhoc-1:
    image: ${HUB_USER}/hudi-hadoop_${HADOOP_VERSION}-hive_${HIVE_VERSION}-sparkadhoc_${SPARK_VERSION}:latest
    hostname: adhoc-1
    container_name: adhoc-1
    env_file:
      - ./hadoop.env
    depends_on:
      - sparkmaster
    ports:
      - '4040:4040'
      # JVM debugging port (mapped to 5006 on the host)
      - "5006:5005"
    environment:
      - "SPARK_MASTER=spark://sparkmaster:7077"
    links:
      - "hivemetastore"
      - "hiveserver"
      - "hive-metastore-postgresql"
      - "namenode"
      - "presto-coordinator-1"
      - "trino-coordinator-1"
    volumes:
      - ${HUDI_WS}:/var/hoodie/ws

  adhoc-2:
    image: ${HUB_USER}/hudi-hadoop_${HADOOP_VERSION}-hive_${HIVE_VERSION}-sparkadhoc_${SPARK_VERSION}:latest
    hostname: adhoc-2
    container_name: adhoc-2
    env_file:
      - ./hadoop.env
    ports:
      # JVM debugging port (mapped to 5005 on the host)
      - "5005:5005"
    depends_on:
      - sparkmaster
    environment:
      - "SPARK_MASTER=spark://sparkmaster:7077"
    links:
      - "hivemetastore"
      - "hiveserver"
      - "hive-metastore-postgresql"
      - "namenode"
      - "presto-coordinator-1"
      - "trino-coordinator-1"
    volumes:
      - ${HUDI_WS}:/var/hoodie/ws

  jupyter-pyspark:
        image: jupyter/pyspark-notebook:spark-3.4.2 # pyspark
        #image: jupyter/all-spark-notebook:spark-3.2.1 # scala
        #image: jupyter/datascience-notebook:latest # julia
        ports:
          - "8888:8888"
        volumes:
          - ./notebooks:/home/jovyan/work/notebooks/

volumes:
  namenode:
  historyserver:
  hive-metastore-postgresql:

networks:
  default:
     name: hudi
